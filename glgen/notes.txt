Types

1. The native ML float format is 64 bit double precision floating point. This will remain so.
However OpenGL 1x and 2.x work most efficiently with 32 bit floats (32 bit floats in hardware), 
and OpenGl 3.0 will not support GL_DOUBLE at all (http://www.opengl.org/discussion_boards/ubbthreads.php?ubb=showflat&Number=229374#Post229374)
	- translation will have to take place
	- or use Bigarrays

2. The native ML int format is 31/63 bits (on 32/64 bit systems respectively). This is incompatible
with native OpenGL.
	 - translation will have to take place
	 - or use Bigarrays

In short: native ML numerical types are incompatible with native GL numerical types.
	* Work directly with the native GL types via Bigarrays
	* Use native types (ints, floats, int arrays, float arrays) and convert to BigArrays where
	necessary
	

Void pointers and striding

Problem: a number of GL functions take a void pointer and a type, stride, and offset
In the GLcaml interface this has to be solved with standard types
	* pass in type glpointer
	* provide functions to convert from *_array to glpointer and back
	* use a polymorphic type and accept only strings and bigarrays in code.


